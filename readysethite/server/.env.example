# === ReadySetHire GenAI server (.env) ===
PORT=8080
REQUIRE_AUTH=true

# LLM provider
OPENAI_API_KEY=REDACTED
LLM_MODEL=gpt-4o-mini

# Tuning
LLM_TEMPERATURE_SUMMARY=0.2
LLM_TEMPERATURE_QUESTIONS=0.7
TRANSCRIPT_MAX_CHARS=1200

# Simple in-memory cache TTL in seconds (0 disables caching)
GENAI_CACHE_TTL_SEC=3600
